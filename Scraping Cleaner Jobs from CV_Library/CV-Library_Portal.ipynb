{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c185607",
   "metadata": {},
   "source": [
    "## Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d94a2b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5774a328",
   "metadata": {},
   "source": [
    "### working with Webdriver to get source of Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "479099b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = webdriver.ChromeOptions()\n",
    "\n",
    "options.add_argument(\"--incognito\")\n",
    "browser = webdriver.Chrome(\"C:\\chromedriver\\chromedriver.exe\", options = options)\n",
    "browser.get(\"https://www.cv-library.co.uk/cleaning-jobs-in-london\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7e41d2",
   "metadata": {},
   "source": [
    "### Beautifying the source Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c864bd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = browser.page_source\n",
    "soup=BeautifulSoup(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5949066b",
   "metadata": {},
   "source": [
    "#### Getting necessary elements from the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2f01471",
   "metadata": {},
   "outputs": [],
   "source": [
    "company = [d.find('a', attrs = {'class' : 'job__company-link'}) for d in  soup.find_all('p', attrs = {'class' : 'job__posted-by'}) if d.find_parents('div',attrs={'class' : 'job__main'})]\n",
    "job = soup.find_all('h2', attrs = {'class' : 'job__title'})\n",
    "city_zip = soup.find_all('span', attrs = {'class' : 'job__details-location'})\n",
    "time = [d.find('span') for d in  soup.find_all('p', attrs = {'class' : 'job__posted-by'}) if d.find_parents('div',attrs={'class' : 'job__main'})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6ab4e851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "12\n",
      "12\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "print(len(company))\n",
    "print(len(job))\n",
    "print(len(city_zip))\n",
    "print(len(time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d879c7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_name = []\n",
    "job_title = []\n",
    "posted_date = []\n",
    "area = []\n",
    "\n",
    "for i in range(len(company)):\n",
    "    company_name.append(company[i].text.strip())\n",
    "    job_title.append(job[i].text.strip())\n",
    "    posted_date.append(time[i].text.strip())\n",
    "    area.append(city_zip[i].text.strip())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ac20f0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2,18):\n",
    "    browser.get(\"https://www.cv-library.co.uk/cleaning-jobs-in-london?page=\"+str(i))\n",
    "    src = browser.page_source\n",
    "    soup=BeautifulSoup(src)\n",
    "    company = [d.find('a', attrs = {'class' : 'job__company-link'}) for d in  soup.find_all('p', attrs = {'class' : 'job__posted-by'}) if d.find_parents('div',attrs={'class' : 'job__main'})]\n",
    "    job = soup.find_all('h2', attrs = {'class' : 'job__title'})\n",
    "    city_zip = soup.find_all('span', attrs = {'class' : 'job__details-location'})\n",
    "    time = [d.find('span') for d in  soup.find_all('p', attrs = {'class' : 'job__posted-by'}) if d.find_parents('div',attrs={'class' : 'job__main'})]    \n",
    "    cn = []\n",
    "    jt = []\n",
    "    pd = []\n",
    "    az = []\n",
    "    for i in range(len(company)):\n",
    "        cn.append(company[i].text.strip())\n",
    "        jt.append(job[i].text.strip())\n",
    "        pd.append(time[i].text.strip())\n",
    "        az.append(city_zip[i].text.strip())\n",
    "    company_name.append(cn)\n",
    "    job_title.append(jt)\n",
    "    posted_date.append(pd)\n",
    "    area.append(az)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9286260b",
   "metadata": {},
   "source": [
    "#### Iterating over all pages of Site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "df10348d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412\n"
     ]
    }
   ],
   "source": [
    "from nltk import flatten\n",
    "\n",
    "company_name_z = flatten(company_name)\n",
    "job_title_z = flatten(job_title)\n",
    "posted_date_z = flatten(posted_date)\n",
    "area_z = flatten(area)\n",
    "print(len(company_name_z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dcf29d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Role</th>\n",
       "      <th>Company</th>\n",
       "      <th>Area/Zip</th>\n",
       "      <th>Posted Datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cleaner</td>\n",
       "      <td>Lidl</td>\n",
       "      <td>West Ealing</td>\n",
       "      <td>a week ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cleaner</td>\n",
       "      <td>Remora Cleaning</td>\n",
       "      <td>City of London, London</td>\n",
       "      <td>4 days ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cleaner</td>\n",
       "      <td>Leaving Care Solutions</td>\n",
       "      <td>London</td>\n",
       "      <td>4 days ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Weekend Cleaner</td>\n",
       "      <td>Deepdene Care Ltd</td>\n",
       "      <td>Streatham, Greater London</td>\n",
       "      <td>22/07/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cleaner</td>\n",
       "      <td>Team CV LTD</td>\n",
       "      <td>Uxbridge, Greater London</td>\n",
       "      <td>a week ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>School Cook</td>\n",
       "      <td>Kedleston Group Ltd</td>\n",
       "      <td>E5, Upper Clapton, Greater London</td>\n",
       "      <td>2 days ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>Head of Soft Services</td>\n",
       "      <td>MMP Consultancy</td>\n",
       "      <td>London</td>\n",
       "      <td>3 days ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>Office Manager</td>\n",
       "      <td>Matchtech</td>\n",
       "      <td>Brentford, London</td>\n",
       "      <td>today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>Practice Manager</td>\n",
       "      <td>Remedicare</td>\n",
       "      <td>Edgware, London</td>\n",
       "      <td>3 days ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>Head of Soft Facilities Management Services</td>\n",
       "      <td>Dutton Recruitment</td>\n",
       "      <td>West London, London</td>\n",
       "      <td>3 days ago</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>412 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Role                 Company  \\\n",
       "0                                        Cleaner                    Lidl   \n",
       "1                                        Cleaner         Remora Cleaning   \n",
       "2                                        Cleaner  Leaving Care Solutions   \n",
       "3                                Weekend Cleaner       Deepdene Care Ltd   \n",
       "4                                        Cleaner             Team CV LTD   \n",
       "..                                           ...                     ...   \n",
       "407                                  School Cook     Kedleston Group Ltd   \n",
       "408                        Head of Soft Services         MMP Consultancy   \n",
       "409                               Office Manager               Matchtech   \n",
       "410                             Practice Manager              Remedicare   \n",
       "411  Head of Soft Facilities Management Services      Dutton Recruitment   \n",
       "\n",
       "                              Area/Zip Posted Datetime  \n",
       "0                          West Ealing      a week ago  \n",
       "1               City of London, London      4 days ago  \n",
       "2                               London      4 days ago  \n",
       "3            Streatham, Greater London      22/07/2021  \n",
       "4             Uxbridge, Greater London      a week ago  \n",
       "..                                 ...             ...  \n",
       "407  E5, Upper Clapton, Greater London      2 days ago  \n",
       "408                             London      3 days ago  \n",
       "409                  Brentford, London           today  \n",
       "410                    Edgware, London      3 days ago  \n",
       "411                West London, London      3 days ago  \n",
       "\n",
       "[412 rows x 4 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame(list(zip(job_title_z, company_name_z, area_z, posted_date_z)), columns=['Role','Company','Area/Zip','Posted Datetime'])\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e372ff7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3eb837cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Role                    Company  \\\n",
      "0           Cleaner                     [Lidl]   \n",
      "1           Cleaner          [Remora Cleaning]   \n",
      "2           Cleaner  [Leaving Care Solutions ]   \n",
      "3   Weekend Cleaner        [Deepdene Care Ltd]   \n",
      "4           Cleaner              [Team CV LTD]   \n",
      "5           Cleaner             [Randstad CPE]   \n",
      "6           Cleaner             [Randstad CPE]   \n",
      "7           Cleaner             [Randstad CPE]   \n",
      "8           Cleaner             [Randstad CPE]   \n",
      "9           Cleaner             [Randstad CPE]   \n",
      "10          Cleaner             [Randstad CPE]   \n",
      "11          Cleaner             [Randstad CPE]   \n",
      "12          Cleaner         [Pertemps Enfield]   \n",
      "13          Cleaner   [Service Care Solutions]   \n",
      "14          Cleaner          [Daniel Owen Ltd]   \n",
      "15          Cleaner                      [PRS]   \n",
      "16          Cleaner           [Pinnacle Group]   \n",
      "17          Cleaner    [Stafforce Recruitment]   \n",
      "18          Cleaner        [Berry Recruitment]   \n",
      "19          Cleaner             [Randstad CPE]   \n",
      "\n",
      "                               Area/Zip Posted Datetime  \n",
      "0                                London     5 hours ago  \n",
      "1                City of London, London      4 days ago  \n",
      "2                                London      4 days ago  \n",
      "3             Streatham, Greater London      22/07/2021  \n",
      "4              Uxbridge, Greater London      a week ago  \n",
      "5                       Wembley, London      22/07/2021  \n",
      "6                       Wembley, London      22/07/2021  \n",
      "7                       Mitcham, London      a week ago  \n",
      "8                       Mitcham, London      a week ago  \n",
      "9                     Greenford, London      a week ago  \n",
      "10                    Greenford, London      30/07/2021  \n",
      "11                     Uxbridge, London      29/07/2021  \n",
      "12  City of Westminster, Greater London      21/07/2021  \n",
      "13                    Islington, London      a week ago  \n",
      "14                      Croydon, London      26/07/2021  \n",
      "15                               Poplar     2 weeks ago  \n",
      "16                Brent, Greater London      19/07/2021  \n",
      "17                               Poplar      26/07/2021  \n",
      "18                      Croydon, London      21/07/2021  \n",
      "19                     Uxbridge, London      21/07/2021  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(25, 4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.head(20))\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea27d693",
   "metadata": {},
   "source": [
    "### Creating a CSV file of finding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d8f1322d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('CV-Library_Portal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05a02ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
